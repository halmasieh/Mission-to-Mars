# Mission-to-Mars
We cover web scraping and various tools needs to extracting information from the active websites. 
This project is done as follows: 
   - Use Chrome Driver tools to identify HTML components.
   - Use BeatifulSoup and Splinter to automate the scrape.
   - Use Mongo to store the data
   - Use Flask to display data


## Resources
- Data Sources: [Nasa wensite](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars)
- Software: [Jupyter Notebook](https://www.anaconda.com/products/individual), [Vs Code](https://sqlite.org/index.html), 
- Module: Splinter, Pandas, Flask, webdriver_manager.chrome, PyMongo, BeautifulSoup


## Results
We plot the results of the analysis so that a visual presentation can help all the stackholders to make a decision about the surf shop location and convince them to inverst in 
starting the surf shop. 

1- Looking at the histogram plot from the June temperature observations. 



![here](https://github.com/halmasieh/surfs_up/blob/main/hist_June.PNG)

